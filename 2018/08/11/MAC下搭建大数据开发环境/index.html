<!DOCTYPE html>
<html  lang="">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 3.8.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Mac环境下搭建大数据开发环境 - Hexo</title>









<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">



<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-1-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Mac环境下搭建大数据开发环境" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-end">
                
                
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-12 has-order-2 column-main">
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2018-08-11T15:33:16.000Z">2018-08-11</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/大数据技术/">大数据技术</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    8 minutes read (About 1196 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                Mac环境下搭建大数据开发环境
            
        </h1>
        <div class="content">
            <h1 id="Mac下搭建大数据开发环境"><a href="#Mac下搭建大数据开发环境" class="headerlink" title="Mac下搭建大数据开发环境"></a>Mac下搭建大数据开发环境</h1><p>环境比较浪费时间，结合自己搭建环境的经验，整理成文档。</p>
<h2 id="安装JDK-和-SCALA"><a href="#安装JDK-和-SCALA" class="headerlink" title="安装JDK 和 SCALA"></a>安装JDK 和 SCALA</h2><p><strong>所有的前置条件是安装JDK，我用的是JDK8.x</strong></p>
<p>java version “1.8.0_162”</p>
<p>Java(TM) SE Runtime Environment (build 1.8.0_162-b12)</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)</p>
<p>Scala code runner version 2.12.4 – Copyright 2002-2017, LAMP/EPFL and Lightbend, Inc.</p>
<h2 id="Spark-V2-3-0"><a href="#Spark-V2-3-0" class="headerlink" title="Spark V2.3.0"></a>Spark V2.3.0</h2><p><img src="file:////Users/wangsiyuan1/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image001.png" alt="img"></p>
<p>Spark安装比较简单，也没什么坑。网上一大堆，随意搞。</p>
<h2 id="vmvare虚拟机"><a href="#vmvare虚拟机" class="headerlink" title="vmvare虚拟机"></a>vmvare虚拟机</h2><p>安装vmware fusion</p>
<h2 id="虚拟下安装Hadoop-amp-hive"><a href="#虚拟下安装Hadoop-amp-hive" class="headerlink" title="虚拟下安装Hadoop &amp; hive"></a>虚拟下安装Hadoop &amp; hive</h2><p>1、hadoop伪分布式部署，版本 2.7.1, sbin/start-all.sh , sbin/stop-all.sh。jps验证其服务是否启动完全</p>
<p>2、hive用mysql（我用的是mariaDB，比安装Mysql省事）做元数据库，版本2.1.1 hive。hive-env.sh,hive-site.xml  hdfs dfs -ls /user/hive/warehouse hive表都存到这个目录下</p>
<p>4、关闭防火墙 永久关闭： chkconfig iptables off  及时生效service iptables stop</p>
<p>5、mac 下 虚拟机vmware Fution</p>
<p>6、ssh -p 22 <a href="mailto:root@172.16.192.130" target="_blank" rel="noopener">root@172.16.192.130</a> ssh链接虚拟机</p>
<p>core-site.xml</p>
 <figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/soft/data/hadoop/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Abase for other temporary directories.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://172.16.192.130:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.native.lib<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Should native hadoop libraries, if present, be used.						<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>hdfs-site.xml</p>
<figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.permissions<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>启动方式：</p>
<p>$HADOOP_HOME/sbin/start-all   </p>
<p> 3825 Jps</p>
<p>3089 DataNode</p>
<p>3252 SecondaryNameNode</p>
<p>2903 NameNode</p>
<p>3405 ResourceManager</p>
<p>3695 NodeManager</p>
<h2 id="虚拟机下安装Mysql-当做Hive的元数据库"><a href="#虚拟机下安装Mysql-当做Hive的元数据库" class="headerlink" title="虚拟机下安装Mysql,当做Hive的元数据库"></a>虚拟机下安装Mysql,当做Hive的元数据库</h2><p>service mysql status 查看mysql是否启动</p>
<p>service mysql start 启动mysql服务</p>
<p>mysql用的mariaDB,yum安装，搜索“centOS 6 yum安装 mariaDB”。mySQL 启动：service mysql start,service mysql status</p>
<p>查看HIVE元数据：</p>
<p>mysql -uroot -p 访问mysql</p>
<p>use hive;</p>
<p>show tables;</p>
<h2 id="虚拟机下安装Hbase"><a href="#虚拟机下安装Hbase" class="headerlink" title="虚拟机下安装Hbase"></a>虚拟机下安装Hbase</h2><p>1、 进入hbase官网，下载hbase1.2.1，因为本地的hadoop版本是2.7.1，要注意hbase和hadoop的兼容性。</p>
<p>2、 下载之后，tar -zxvf hbase-1.2.1-bin.tar.gz</p>
<p>3、 修改hbase conf目录下hbase-site.xml文件</p>
<figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="line">	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">      <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.rootdir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://192.168.2.100:9000/hbase<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> </span><br><span class="line">注意别忘了端口号，URL要和hadoop core-site.xml保持一致</span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.cluster.distributed<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/soft/zkdata<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>注意/soft/zkdata要有读写权限</span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>4、 修改conf 下的 hbase-env.sh</p>
<p>export JAVA_HOME=/soft/jdk1.8.0_171</p>
<p>export HBASE_CLASSPATH=$HADOOP_HOME/conf</p>
<p>export HBASE_MANAGES_ZK=true 这个值默认是true的，作用是让HBase启动的时候同时也启动zookeeper.</p>
<p>5、 启动hbase ./start-hbase.sh,执行JPS会看到如下进程。</p>
<p>[root@localhost bin]# jps</p>
<p>20979 DataNode</p>
<p>21315 ResourceManager</p>
<p>22180 HRegionServer</p>
<p>21605 NodeManager</p>
<p>21158 SecondaryNameNode</p>
<p>21961 HQuorumPeer</p>
<p>23116 Jps</p>
<p>22060 HMaster</p>
<p>20845 NameNode</p>
<p>6、 启动Hbase shell, bin/hbase shell，执行命令测试下Hbase shell能否正常工作。</p>
<p>hbase(main):001:0&gt; list “test”</p>
<p>TABLE                                                                                                            </p>
<p>test                                                                                                             </p>
<p>1 row(s) in 0.3870 seconds</p>
<p>=&gt; [“test”]</p>
<h2 id="遇到的雷"><a href="#遇到的雷" class="headerlink" title="遇到的雷"></a>遇到的雷</h2><p>本地SPARK连HIVE，需要把虚拟机中 hive_home/conf/hive-site.xml 复制到spark_home/conf下一份，并且需要把mysql驱动放到$spark_home/jars中</p>
<p>需要把虚拟机中的MYSQL （hive元数据库）权限调成任何IP都能访问。GRANT ALL PRIVILEGES ON <em>.</em> TO  ‘root‘@’%’ IDENTIFIED BY ‘123456’; 执行flush privileges;刷新权限。</p>
<p>如果遇到这个错误。 Hive Schema version 1.2.0 does not match metastore’s schema version 2.1.0 Metastore is not upgraded or corrupt。 需要把hive-site.xml设置成hive.metastore.schema.verification = false</p>
<p>hive.exec.local.scratchdir，hive.querylog.location，hive.server2.logging.operation.log.location 都配置成 /tmp/root。之前放到apache-hive目录下，会报错。</p>
<p>ElasticSearch-hadoop 6.2.3 匹配es 6.x ;ElasticSearch-hadoop 5.2.3 匹配 es 5.x </p>
<p>mac 改成静态IP <a href="https://blog.csdn.net/zhishengqianjun/article/details/77046796" target="_blank" rel="noopener">https://blog.csdn.net/zhishengqianjun/article/details/77046796</a></p>
<p>本地调用Hbase API的时候，需要执行以下三个步骤，不然就会找不到regionServer反复重试，照成阻塞。</p>
<p>1、 配置Linux的hostname :vim /etc/sysconfig/network</p>
<p>NETWORKING=yes</p>
<p>HOSTNAME=master</p>
<p>2、 配置Linux的hosts，映射ip的hostname的关系</p>
<p>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</p>
<p>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</p>
<p>193.168.2.100 master</p>
<p>3、配置访问windows的hosts，192.168.2.100 master</p>
<h2 id="mac下安装ElasticSearch"><a href="#mac下安装ElasticSearch" class="headerlink" title="mac下安装ElasticSearch"></a>mac下安装ElasticSearch</h2><p>特别简单，自行google</p>
<p>brew services restart elasticsearch</p>
<p>brew services restart kibana</p>
<p>elasticsearch –version 观察es版本</p>
<p>安装目录： /usr/local/Cellar/elasticsearch/6.2.4</p>
<p>brew info elasticsearch 可以查看elasticsearch的详情。很实用的命令。</p>
<h2 id="Mac下vmware-静态IP"><a href="#Mac下vmware-静态IP" class="headerlink" title="Mac下vmware 静态IP"></a>Mac下vmware 静态IP</h2><p>虚拟机默认是动态分配IP，一旦IP变更，大数据的环境会有问题。静态IP是必须要解决的问题。</p>
<p><a href="https://blog.csdn.net/zhishengqianjun/article/details/77046796" target="_blank" rel="noopener">https://blog.csdn.net/zhishengqianjun/article/details/77046796</a></p>
<p>照着这个帖子，一步一步来。稳稳的。</p>
<h2 id="Idea中执行spark-sql"><a href="#Idea中执行spark-sql" class="headerlink" title="Idea中执行spark sql"></a>Idea中执行spark sql</h2><p><img src="file:////Users/wangsiyuan1/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image002.png" alt="img"></p>
<p>需要把spark_home/conf下的hive-site.xml复制到resource目录下。</p>
<p>另外，如果pom中没有mysql jar包的话，需要加入。</p>
<h2 id="将hdfs-文件关联到hive上"><a href="#将hdfs-文件关联到hive上" class="headerlink" title="将hdfs 文件关联到hive上"></a>将hdfs 文件关联到hive上</h2><p>1、 首先在虚拟机hive上，创建好表结构</p>
<p>2、 登录线上的hive，找到hive对应的HDFS文件，copy一个part下来。</p>
<p>3、 传到虚拟机的hdfs上</p>
<p>4、执行ALTER TABLE xxx ADD PARTITION (dt=’2013-02-28’)<br> LOCATION ‘/wsy’; （如果是lzo压缩过的文件，执行lzop -dv 001008_0.lzo 解压缩，不然hive读的时候会乱码）</p>
<p>5、 大功告成。</p>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/Hbase/">Hbase</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2018/08/11/JVM内存区域/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">JVM内存区域</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2018/08/11/Spring初始化/">
                <span class="level-item">Spring初始化源码分析</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Mac环境下搭建大数据开发环境" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("");</script>

<script>
var IcarusThemeSettings = {
    article: {
        highlight: {
            clipboard: true,
            fold: 'true'
        }
    }
};
</script>


    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>




<script src="/js/main.js" defer></script>

    
</body>
</html>